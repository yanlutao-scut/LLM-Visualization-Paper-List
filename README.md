# LLM-Visualization-Paper-List



## 0. Chart Captioning

**Natural Language Dataset Generation Framework for Visualizations Powered by Large Language Models** \
Hyung-Kwon Ko, Hyeon Jeon, Gwanmo Park, Dae Hyun Kim, Nam Wook Kim, Juho Kim, Jinwook Seo \
[CHI 2024](https://arxiv.org/abs/2309.10245) • [Code](https://github.com/hyungkwonko/chart-llm)

**VisText: A Benchmark for Semantically Rich Chart Captioning** \
Benny J. Tang, Angie Boggust, Arvind Satyanarayan \
[ACL 2023 Outstanding paper](https://aclanthology.org/2023.acl-long.401.pdf) • [Code](https://github.com/mitvis/vistext)

## 1. Chart Question Answering

**Advancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning** \
Xingchen Zeng, Haichuan Lin, Yilin Ye, Wei Zeng \
[VIS 2024](https://arxiv.org/abs/2407.20174) • [Code](https://github.com/zengxingchen/ChartQA-MLLM)

**ChartMoE: Mixture of Expert Connector for Advanced Chart Understanding** \
Zhengzhuo Xu, Bowen Qu, Yiyan Qi, Sinan Du, Chengjin Xu, Chun Yuan, Jian Guo \
[arXiv, 5 Sep 2024](https://arxiv.org/abs/2409.03277) • [Code](https://chartmoe.github.io/)


## 2. Generic Multimodal Large Language Model
**EAGLE: Exploring The Design Space for Multimodal LLMs with Mixture of Encoders** \
Min Shi*, Fuxiao Liu*, Shihao Wang, Shijia Liao, Subhashree Radhakrishnan, De-An Huang, Hongxu Yin, Karan Sapra, Yaser Yacoob, Humphrey Shi,
Bryan Catanzaro, Andrew Tao, Jan Kautz, Zhiding Yu, Guilin Liu \
[arXiv, 28 Aug 2024](https://arxiv.org/abs/2408.15998) • [code](https://github.com/NVlabs/EAGLE)

**Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs** \
Shengbang Tong*, Ellis Brown*, Penghao Wu*, Sanghyun Woo, Manoj Middepogu, Sai Charitha Akula, Jihan Yang, Shusheng Yang, Adithya Iyer, Xichen Pan, Austin Wang, Rob Fergus, Yann LeCun, Saining Xie \
[arXiv, 24 Jun 2024](https://arxiv.org/abs/2408.15998) • [code](https://github.com/cambrian-mllm/cambrian)
